# Generated by Django 4.2.4 on 2025-09-26 06:25

from django.db import migrations, models
import django.utils.timezone


class Migration(migrations.Migration):

    dependencies = [
        ('app', '0011_rename_bns_act_answer_extension_data_dpdp_dpdp_act_answer_and_more'),
    ]

    operations = [
        migrations.CreateModel(
            name='Githhub_Model_API',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('API_Path_Githhub', models.TextField(blank=True, default='', null=True)),
                ('API_Path_Azure', models.TextField(blank=True, default='', null=True)),
                ('Updated_on', models.DateTimeField(default=django.utils.timezone.now)),
            ],
        ),
        migrations.AlterField(
            model_name='bareactsagentconfiguration',
            name='Answer_Model',
            field=models.CharField(choices=[('gemini-2.0-flash', 'GOOGLE>gemini-2.0-flash'), ('gemini-2.5-flash', 'GOOGLE>gemini-2.5-flash'), ('gemini-2.5-pro', 'GOOGLE>gemini-2.5-pro'), ('gemini-1.5-flash', 'GOOGLE>gemini-1.5-flash'), ('gemma3:4b', 'OLLAMA>gemma3:4b'), ('llama3.2:latest', 'OLLAMA>llama3.2:latest'), ('llama3.2:1b', 'OLLAMA>llama3.2:1b'), ('deepseek-r1:latest', 'OLLAMA>deepseek-r1:latest'), ('gemma2:2b', 'OLLAMA>gemma2:2b'), ('deepseek-r1:1.5b', 'OLLAMA>deepseek-r1:1.5b'), ('llama2:chat', 'OLLAMA>llama2:chat'), ('llama3.2:latest', 'OLLAMA>llama3.2:latest'), ('openai/gpt-5<(github)', 'GithubModels>Openai-GPT-5')], default='gemini-2.5-pro', max_length=50),
        ),
        migrations.AlterField(
            model_name='bareactsagentconfiguration',
            name='Grader_Model',
            field=models.CharField(choices=[('gemini-2.0-flash', 'GOOGLE>gemini-2.0-flash'), ('gemini-2.5-flash', 'GOOGLE>gemini-2.5-flash'), ('gemini-2.5-pro', 'GOOGLE>gemini-2.5-pro'), ('gemini-1.5-flash', 'GOOGLE>gemini-1.5-flash'), ('gemma3:4b', 'OLLAMA>gemma3:4b'), ('llama3.2:latest', 'OLLAMA>llama3.2:latest'), ('llama3.2:1b', 'OLLAMA>llama3.2:1b'), ('deepseek-r1:latest', 'OLLAMA>deepseek-r1:latest'), ('gemma2:2b', 'OLLAMA>gemma2:2b'), ('deepseek-r1:1.5b', 'OLLAMA>deepseek-r1:1.5b'), ('llama2:chat', 'OLLAMA>llama2:chat'), ('llama3.2:latest', 'OLLAMA>llama3.2:latest'), ('openai/gpt-5<(github)', 'GithubModels>Openai-GPT-5')], default='gemini-2.5-flash', max_length=50),
        ),
        migrations.AlterField(
            model_name='bareactsagentconfiguration',
            name='Model_Name',
            field=models.CharField(choices=[('gemini-2.0-flash', 'GOOGLE>gemini-2.0-flash'), ('gemini-2.5-flash', 'GOOGLE>gemini-2.5-flash'), ('gemini-2.5-pro', 'GOOGLE>gemini-2.5-pro'), ('gemini-1.5-flash', 'GOOGLE>gemini-1.5-flash'), ('gemma3:4b', 'OLLAMA>gemma3:4b'), ('llama3.2:latest', 'OLLAMA>llama3.2:latest'), ('llama3.2:1b', 'OLLAMA>llama3.2:1b'), ('deepseek-r1:latest', 'OLLAMA>deepseek-r1:latest'), ('gemma2:2b', 'OLLAMA>gemma2:2b'), ('deepseek-r1:1.5b', 'OLLAMA>deepseek-r1:1.5b'), ('llama2:chat', 'OLLAMA>llama2:chat'), ('llama3.2:latest', 'OLLAMA>llama3.2:latest'), ('openai/gpt-5<(github)', 'GithubModels>Openai-GPT-5')], default='gemini-2.0-flash', max_length=50),
        ),
        migrations.AlterField(
            model_name='bareactsagentconfiguration',
            name='Retriever_Model',
            field=models.CharField(choices=[('gemini-2.0-flash', 'GOOGLE>gemini-2.0-flash'), ('gemini-2.5-flash', 'GOOGLE>gemini-2.5-flash'), ('gemini-2.5-pro', 'GOOGLE>gemini-2.5-pro'), ('gemini-1.5-flash', 'GOOGLE>gemini-1.5-flash'), ('gemma3:4b', 'OLLAMA>gemma3:4b'), ('llama3.2:latest', 'OLLAMA>llama3.2:latest'), ('llama3.2:1b', 'OLLAMA>llama3.2:1b'), ('deepseek-r1:latest', 'OLLAMA>deepseek-r1:latest'), ('gemma2:2b', 'OLLAMA>gemma2:2b'), ('deepseek-r1:1.5b', 'OLLAMA>deepseek-r1:1.5b'), ('llama2:chat', 'OLLAMA>llama2:chat'), ('llama3.2:latest', 'OLLAMA>llama3.2:latest'), ('openai/gpt-5<(github)', 'GithubModels>Openai-GPT-5')], default='gemini-2.0-flash', max_length=50),
        ),
        migrations.AlterField(
            model_name='bareactsagentconfiguration',
            name='Router_Model',
            field=models.CharField(choices=[('gemini-2.0-flash', 'GOOGLE>gemini-2.0-flash'), ('gemini-2.5-flash', 'GOOGLE>gemini-2.5-flash'), ('gemini-2.5-pro', 'GOOGLE>gemini-2.5-pro'), ('gemini-1.5-flash', 'GOOGLE>gemini-1.5-flash'), ('gemma3:4b', 'OLLAMA>gemma3:4b'), ('llama3.2:latest', 'OLLAMA>llama3.2:latest'), ('llama3.2:1b', 'OLLAMA>llama3.2:1b'), ('deepseek-r1:latest', 'OLLAMA>deepseek-r1:latest'), ('gemma2:2b', 'OLLAMA>gemma2:2b'), ('deepseek-r1:1.5b', 'OLLAMA>deepseek-r1:1.5b'), ('llama2:chat', 'OLLAMA>llama2:chat'), ('llama3.2:latest', 'OLLAMA>llama3.2:latest'), ('openai/gpt-5<(github)', 'GithubModels>Openai-GPT-5')], default='gemini-2.0-flash', max_length=50),
        ),
        migrations.AlterField(
            model_name='langgraph_deployed_api',
            name='API_Path',
            field=models.TextField(blank=True, default='', null=True),
        ),
        migrations.AlterField(
            model_name='reflexionagentconfiguration',
            name='Reflexion_Model',
            field=models.CharField(choices=[('gemini-2.0-flash', 'GOOGLE>gemini-2.0-flash'), ('gemini-2.5-flash', 'GOOGLE>gemini-2.5-flash'), ('gemini-2.5-pro', 'GOOGLE>gemini-2.5-pro'), ('gemini-1.5-flash', 'GOOGLE>gemini-1.5-flash'), ('gemma3:4b', 'OLLAMA>gemma3:4b'), ('llama3.2:latest', 'OLLAMA>llama3.2:latest'), ('llama3.2:1b', 'OLLAMA>llama3.2:1b'), ('deepseek-r1:latest', 'OLLAMA>deepseek-r1:latest'), ('gemma2:2b', 'OLLAMA>gemma2:2b'), ('deepseek-r1:1.5b', 'OLLAMA>deepseek-r1:1.5b'), ('llama2:chat', 'OLLAMA>llama2:chat'), ('llama3.2:latest', 'OLLAMA>llama3.2:latest'), ('openai/gpt-5<(github)', 'GithubModels>Openai-GPT-5')], default='gemini-2.5-pro', max_length=50),
        ),
    ]
